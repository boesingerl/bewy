{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import tarfile\n",
    "from dask.delayed import delayed\n",
    "import scipy\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import surprise\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_tracks = pd.read_csv('data/features.csv')\n",
    "df_1kfamous   = pd.read_csv('data/df_1kfamous.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Using Surprise library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup dataframe to only take the famous tracks computed before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many unique users and tracks we have !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1kfamous['user-id'].unique()), len(df_1kfamous['track-id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute scoring for each track id based on mean and standard deviation of users plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and std for normalization\n",
    "user_means = df_1kfamous.groupby('user-id').mean()['plays']\n",
    "user_std   = df_1kfamous.groupby('user-id').std(ddof=0)['plays'].replace(0, 1)\n",
    "\n",
    "# normalize plays\n",
    "df_1kfamous['norm_plays'] = df_1kfamous.apply(lambda x : (x['plays'] - user_means.loc[x['user-id']])/(user_std.loc[x['user-id']]), axis=1)\n",
    "\n",
    "# linear binning on the number of plays\n",
    "df_1kfamous['cat_plays'] = pd.cut(df_1kfamous['norm_plays'], bins=10, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# quartile binning\n",
    "df_1kfamous['qcat_plays'] = pd.qcut(df_1kfamous['norm_plays'], 10, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['qcat_plays'].astype(int).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['qcat_plays'] = df_1kfamous['qcat_plays'].astype(int)\n",
    "mean_per_track = df_1kfamous.groupby('track-id').mean()['qcat_plays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['test_plays'] = df_1kfamous.apply(lambda x : x['qcat_plays'] - mean_per_track.loc[x['track-id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['test_plays'].astype(int).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear binning on the number of plays\n",
    "df_1kfamous['new_plays'] = pd.cut(df_1kfamous['test_plays'], bins=10, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['new_plays'].astype(int).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['new_plays'] = df_1kfamous['new_plays'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Users with low number of listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['user_count'] = df_1kfamous.groupby('user-id').transform(lambda x : x.count())['plays']\n",
    "\n",
    "df_reduced = df_1kfamous[df_1kfamous['user_count'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup surprise datastructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Reader class\n",
    "# Our rating scale is from 1 to 10\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# now we apply the binning\n",
    "ndata = Dataset.load_from_df(df_reduced[['user-id', 'track-id', 'new_plays']], reader)\n",
    "\n",
    "# We'll split into the trainset and testset\n",
    "trainset, testset = surprise.model_selection.train_test_split(ndata, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the SVD and obtaining the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "full_set = ndata.build_full_trainset()\n",
    "\n",
    "final_algorithm = SVD(n_factors=1000, n_epochs=20, biased=True)\n",
    "final_algorithm.fit(full_set)\n",
    "\n",
    "# And we test it\n",
    "#test_predictions = final_algorithm.test(testset)\n",
    "\n",
    "# Get the accuracy\n",
    "#print(f\"The RMSE is {accuracy.rmse(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = final_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(user_id, predict_df, tracks_df=famous_tracks, plays_df=df_1kfamous, k=10):\n",
    "    \n",
    "    predicted_tracks = list(predict_df.sort_values(by='prediction', ascending=False).head(k)[0])\n",
    "    \n",
    "    predicted_artists = set(tracks_df[tracks_df['musicbrainz-track-id'].isin(predicted_tracks)]['musicbrainz-artist-id'])\n",
    "    \n",
    "    listened_artists = set(plays_df[plays_df['user-id'] == user_id]['artist-id'])\n",
    "    \n",
    "    return len(predicted_artists.intersection(listened_artists))/len(predicted_artists)\n",
    "\n",
    "def compute_map(user_id, predict_df,tracks_df=famous_tracks, plays_df=df_1kfamous, k=10):\n",
    "    \n",
    "    precisions = [compute_precision(user_id, predict_df, tracks_df=famous_tracks, plays_df=df_1kfamous, k=k_) for k_ in np.arange(k)+1]\n",
    "    \n",
    "    return np.mean(precisions)\n",
    "\n",
    "def compute_average_precision_map(df,algo,k=10):\n",
    "    precisions = []\n",
    "    maps = []\n",
    "    all_tracks = df['track-id'].unique()\n",
    "    \n",
    "    for user in tqdm(df['user-id'].unique()):\n",
    "\n",
    "        # compute predictions\n",
    "        predicts = [algo.predict(uid=user, iid=x).est for x in all_tracks]\n",
    "\n",
    "        # create df of tracks\n",
    "        predicts_df = pd.Series(all_tracks).to_frame()\n",
    "\n",
    "        # add predictions to previous df\n",
    "        predicts_df['prediction'] = predicts\n",
    "        \n",
    "        # compute values\n",
    "        precisions.append(compute_precision(user, predicts_df,k=k))\n",
    "        maps.append(compute_map(user, predicts_df,k=k))\n",
    "        \n",
    "    return (np.mean(precisions), np.std(precisions)), (np.mean(maps), np.std(maps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIIIIIID SEAAAAARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "\n",
    "def launch_grid_search(algos, algo_names):\n",
    "    kf = KFold(n_splits=3)\n",
    "    results = {}\n",
    "\n",
    "    for algo, name in tqdm(zip(algos, algo_names),total=len(algos)):\n",
    "\n",
    "        results[name] = {'rmse':[], 'mae':[], 'mean_precision@k':None, 'mean_map@k': None, 'std_precision@k':None, 'std_map@k':None}\n",
    "\n",
    "        for trainset, testset in kf.split(data):\n",
    "\n",
    "            # train and test algorithm.\n",
    "            algo.fit(trainset)\n",
    "            predictions = algo.test(testset)\n",
    "\n",
    "            # Compute RMSE, MAE\n",
    "            results[name]['rmse'].append(accuracy.rmse(predictions, verbose=False))\n",
    "            results[name]['mae'].append(accuracy.mae(predictions, verbose=False))\n",
    "\n",
    "            if results[name]['mean_precision@k'] is None:\n",
    "                # Compute Rank based metrics\n",
    "                (mean_precision, std_precision), (mean_map, std_map) = compute_average_precision_map(df_1kfamous,algo)\n",
    "                results[name]['mean_precision@k'] = mean_precision\n",
    "                results[name]['mean_map@k']       = mean_map\n",
    "                results[name]['std_precision@k']  = std_precision\n",
    "                results[name]['std_map@k']        = std_map\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "algos = [SVD(),\n",
    "         SVD(biased=False),\n",
    "         NMF(),\n",
    "         KNNBaseline(sim_options={'user_based':True, 'name':'pearson_baseline'}),\n",
    "         KNNBaseline(sim_options={'user_based':False, 'name':'pearson_baseline'}),\n",
    "         CoClustering(n_cltr_u=5, n_cltr_i=20)\n",
    "        ]\n",
    "\n",
    "algo_names = ['SVD', 'PMF', 'NMF', 'User-based KNN with Baseline', 'Item-based KNN with Baseline']\n",
    "\n",
    "# results = launch_grid_search(algos, algo_names)\n",
    "# f = open('gridresults.pkl', 'wb')   # Pickle file is newly created where foo1.py is\n",
    "# pickle.dump(results, f)          # dump data to f\n",
    "# f.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gridresults.pkl', 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "\n",
    "results_df = pd.DataFrame(results).applymap(lambda x : np.mean(x))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "results_df.loc[['mean_map@k']].T.plot.bar(yerr=results_df.loc['std_map@k'],ax=axs[0])\n",
    "\n",
    "results_df.loc[['mean_precision@k']].T.plot.bar(yerr=results_df.loc['std_precision@k'], ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in results_df.index:\n",
    "    plt.figure(figsize=(15,5))\n",
    "    sns.barplot(data=results_df.loc[col].to_frame().T)\n",
    "    plt.gca().set(title=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on sampled users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample user\n",
    "sampled_user = df_1kfamous['user-id'].sample(n=1).iloc[0]\n",
    "\n",
    "# compute predictions\n",
    "predicts = [final_algorithm.predict(uid=sampled_user, iid=x).est for x in df_1kfamous['track-id'].unique()]\n",
    "\n",
    "# create df of tracks\n",
    "predicts_df = pd.Series(df_1kfamous['track-id'].unique()).to_frame()\n",
    "\n",
    "# add predictions to previous df\n",
    "predicts_df['prediction'] = predicts\n",
    "\n",
    "# get best songs predicted from svd\n",
    "predicted_best = predicts_df.sort_values(by='prediction', ascending=False).head(5)[0]\n",
    "\n",
    "# get the best songs by track\n",
    "single_user = df_1kfamous[df_1kfamous['user-id'] == sampled_user]\n",
    "target_best = single_user.sort_values(by='plays',ascending=False).head(5)['track-id']\n",
    "print('Target')\n",
    "print(famous_tracks[famous_tracks['musicbrainz-track-id'].isin(target_best)][['track-name','artist-name']].to_markdown())\n",
    "print('Predicted')\n",
    "print(famous_tracks[famous_tracks['musicbrainz-track-id'].isin(predicted_best)][['track-name','artist-name']].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best tracks for a random user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best songs by track\n",
    "single_user = df_1kfamous[df_1kfamous['user-id'] == 'user_000016']\n",
    "target_best = single_user.sort_values(by='plays',ascending=False).head(5)['track-id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions\n",
    "predicts = [final_algorithm.predict(uid='user_000016', iid=x)[3] for x in df_1kfamous['track-id'].unique()]\n",
    "\n",
    "# create df of tracks\n",
    "predicts_df = pd.Series(df_1kfamous['track-id'].unique()).to_frame()\n",
    "\n",
    "# add predictions to previous df\n",
    "predicts_df['prediction'] = predicts\n",
    "\n",
    "# get best songs predicted from svd\n",
    "predicted_best = predicts_df.sort_values(by='prediction', ascending=False).head(5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual most listened tracks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous[df_1kfamous['track-id'].isin(target_best)][['track-name','artist-name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best tracks retrieved by SVD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous[df_1kfamous['track-id'].isin(predicted_best)][['track-name','artist-name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Set SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_algorithm = SVDpp(n_factors=100, n_epochs=20, reg_all=0.05)\n",
    "final_algorithm.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x2d = pca.fit_transform(final_algorithm.pu)\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(2,12))\n",
    "\n",
    "visualizer.fit(x2d)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "x2d = pca.fit_transform(final_algorithm.pu)\n",
    "\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(x2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userids = [full_set.to_raw_uid(uid) for uid in range(final_algorithm.pu.shape[0])]\n",
    "\n",
    "userlabels = pd.DataFrame({'userid':userids,'label':model.labels_, 'x': x2d[:,0], 'y':x2d[:,1]} )\n",
    "\n",
    "fig = px.scatter(userlabels,'x','y', color='label', custom_data=['userid'])\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"x: %{x}\",\n",
    "        \"y: %{y}\",\n",
    "        \"user-id: %{customdata[0]}\"\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users per cluster :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(model.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_k_users(df, k, num_clusters=5):\n",
    "    \n",
    "    # select one from each cluster\n",
    "    num_per = np.bincount(list(map(lambda x : x%num_clusters, np.arange(k))))\n",
    "    \n",
    "    # sample user from number\n",
    "    return sum([list(df[df['label'] == i]['userid'].sample(n=x).values) for i,x in enumerate(num_per)], [])\n",
    "    \n",
    "users = sample_k_users(userlabels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_from_users(df, users):\n",
    "    # get list of all tracks\n",
    "    tracks = df['track-id'].unique()\n",
    "    \n",
    "    # compute prediction for all users, all tracks\n",
    "    predicts = [[final_algorithm.predict(uid=uid, iid=iid).est for uid in users] for iid in tracks]\n",
    "    \n",
    "    # create df from results\n",
    "    predicts_df = pd.DataFrame(predicts)\n",
    "    \n",
    "    # add information about track, user\n",
    "    predicts_df.index = tracks\n",
    "    predicts_df.columns = users\n",
    "    \n",
    "    return predicts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_variance(predicts_df):\n",
    "    # init value\n",
    "    values = np.zeros(predicts_df.shape[0])\n",
    "    \n",
    "    # iterate over all pairs of users\n",
    "    for col1 in predicts_df.columns:\n",
    "        for col2 in predicts_df.columns:\n",
    "            if col1 != col2:\n",
    "                # add difference\n",
    "                values += np.abs(predicts_df[col1] - predicts_df[col2])\n",
    "                \n",
    "    return values * 2/(predicts_df.shape[1] * (predicts_df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_ratings(predicts_df, relevance_coeff = 0.5, max_rating=10):\n",
    "    # compute relevance\n",
    "    average_relevance = predicts_df.mean(axis=1).to_frame('relevance') / max_rating\n",
    "    # compute variance\n",
    "    variance = disagreement_variance(predicts_df).to_frame('variance')\n",
    "    # join back variance and relevance in a single rating\n",
    "    group_ratings = average_relevance.join(variance)\n",
    "    group_ratings['rating'] = (relevance_coeff*group_ratings['relevance']) + (1-relevance_coeff)*(1-group_ratings['variance'])\n",
    "    return group_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of number of users on the relevance (when sampling as many from each cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_sampler       = lambda df,k : list(df['userid'].sample(n=k))\n",
    "first_cluster_sampler = lambda df,k : list(df[df['label'] == 0]['userid'].sample(n=k))\n",
    "\n",
    "samplers      = [sample_k_users, uniform_sampler, first_cluster_sampler]\n",
    "sampler_names = ['Uniform per cluster sampler', 'Uniform Sampler', 'Single cluster sampler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = {}\n",
    "\n",
    "all_ks = np.unique(np.geomspace(start=5, stop=100, num=10, dtype=int))\n",
    "for sampler, sampler_name in zip(samplers, sampler_names):\n",
    "    \n",
    "    mean_ratings[sampler_name] = []\n",
    "    \n",
    "    for k in tqdm(all_ks):\n",
    "        # sample k users from the clusters\n",
    "        users = sampler(userlabels,k)\n",
    "\n",
    "        # compute predictions for the given users\n",
    "        predicts_df = predictions_from_users(df_reduced, users)\n",
    "\n",
    "        # compute group ratings\n",
    "        group_ratings = compute_group_ratings(predicts_df)\n",
    "\n",
    "        # mean rating for top_k\n",
    "        mean_ratings[sampler_name].append(group_ratings.sort_values(by='rating', ascending=False).head(10)['rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mean_ratings).set_index(all_ks).plot(kind='bar')\n",
    "plt.gca().set(title=f'Relevance (in [0,1]) as a function of group size', xlabel='Group Size', ylabel='Relevance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Relevance coefficient (0 => Minimize Disagreement, 1 => Maximize Average relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "# sample k users from the clusters\n",
    "users = first_cluster_sampler(userlabels,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    display(df_1kfamous[df_1kfamous['user-id'] == user].sort_values(by='plays',ascending=False).head(3)[['track-name', 'artist-name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relevance_coeff in [0,0.5,1]:\n",
    "    # compute predictions for the given users\n",
    "    predicts_df = predictions_from_users(df_reduced, users)\n",
    "\n",
    "    # compute group ratings\n",
    "    group_ratings = compute_group_ratings(predicts_df, relevance_coeff=relevance_coeff)\n",
    "\n",
    "    # mean rating for top_k\n",
    "    top10_ratings = group_ratings.sort_values(by='rating', ascending=False).head(5)\n",
    "    \n",
    "    \n",
    "    display(famous_tracks.merge(top10_ratings.reset_index(), right_on='index', left_on='musicbrainz-track-id')[['track-name', 'artist-name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_ratings.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per user top-k from svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_tracks[famous_tracks['musicbrainz-track-id'].isin((list(ratings_df['user_000378'].sort_values(ascending=False).index)[:10]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['user_000657'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.index[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.loc['c697b759-2ef6-43bb-a97a-2c56409abade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1 = famous_tracks.set_index('musicbrainz-track-id').to_dict(orient='index')\n",
    "dic_trackname = {a:b['track-name'] for a,b in dic1.items()}\n",
    "dic_artist_id = {a:b['musicbrainz-artist-id'] for a,b in dic1.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ratings_df.T.melt(ignore_index=False).reset_index().groupby('index')\n",
    "per_user_pref = gb.apply(lambda x : set(x.sort_values(by='value',ascending=False).head(10)['variable']))\n",
    "user_pref = pd.DataFrame([list(x) for x in list(per_user_pref)]).T\n",
    "user_pref.columns = user_sample\n",
    "user_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artists = df_1kfamous.groupby('user-id').apply(lambda x : set(x['artist-id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_user_listens = {a:b for a,b in zip(user_sample,list(map(lambda x: user_artists.loc[x], user_sample)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_art = user_pref.applymap(dic_artist_id.get)\n",
    "for column in user_art:\n",
    "    user_art[column] = user_art[column].isin(per_user_listens[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref.applymap(dic_trackname.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Base Recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_tracks_rec = pd.read_csv('data/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data = ['key', 'mode', 'time_signature', 'type']\n",
    "continious_data = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in discrete_data :\n",
    "    famous_tracks_rec[c] = famous_tracks_rec[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_attrs = famous_tracks_rec.set_index(['musicbrainz-track-id'])[continious_data + discrete_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "euclidean_genres_distance = dist.pairwise(filtered_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_genres_distance = euclidean_genres_distance / np.max(euclidean_genres_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(euclidean_genres_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_tracks = famous_tracks_rec['genres']\n",
    "genres_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handling of the set of genres was inspired by the following work : https://towardsdatascience.com/dealing-with-list-values-in-pandas-dataframes-a177e534f173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_tracks = genres_tracks.apply(lambda x : list(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = set()\n",
    "\n",
    "for g in genres_tracks:\n",
    "    for i in g :\n",
    "        unique_genres.add(i)\n",
    "        \n",
    "unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_col_for_genre(tracks, unique_genres) :\n",
    "    bool_dict = {}\n",
    "    for i, item in enumerate(unique_genres):\n",
    "        bool_dict[item] = tracks.apply(lambda x: item in x)\n",
    "    return pd.DataFrame(bool_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_bool = generate_col_for_genre(genres_tracks, unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_bool.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = DistanceMetric.get_metric('hamming')\n",
    "hamming_genres_distance = dist.pairwise(genres_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_genres_distance /= np.max(hamming_genres_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hamming_genres_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_distance = hamming_genres_distance*0.5 + euclidean_genres_distance*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_distance = pd.DataFrame(global_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_closest_songs(song, n) :    \n",
    "    return list(global_distance.nsmallest(n + 1, 0).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_track = famous_tracks_rec.iloc[0]\n",
    "songs = find_n_closest_songs(target_track, 10)\n",
    "famous_tracks_rec.loc[songs][['artist-name', 'track-name', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Non-conclusive attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import time \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_users, no_items, no_ratings = (len(df_1kfamous['user-id'].unique()),\n",
    "                                  len(df_1kfamous['track-id'].unique()),\n",
    "                                  len(df_1kfamous.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1kfamous['original_user_id'] = df_1kfamous['user-id']\n",
    "df_1kfamous['original_item_id'] = df_1kfamous['track-id']\n",
    "df_1kfamous['user_id'] = df_1kfamous['user-id'].astype('category').cat.codes\n",
    "df_1kfamous['item_id'] = df_1kfamous['track-id'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ratings, test_ratings = train_test_split(df_1kfamous,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_users, no_items, no_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings.shape, train_ratings['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings.shape, test_ratings['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shallow_model(no_factors, no_users, no_items):\n",
    "    # User branch\n",
    "    user_id = tf.keras.layers.Input(shape=[1], name='user_id')\n",
    "    user_matrix = tf.keras.layers.Embedding(no_users+1, no_factors, name='user_matrix')(user_id)\n",
    "    user_vector = tf.keras.layers.Flatten(name='user_vector')(user_matrix)\n",
    "    # Item branch\n",
    "    item_id = tf.keras.layers.Input(shape=[1], name='item_id')\n",
    "    item_matrix = tf.keras.layers.Embedding(no_items+1, no_factors, name='item_matrix')(item_id)\n",
    "    item_vector = tf.keras.layers.Flatten(name='item_vector')(item_matrix)\n",
    "    # Dot product \n",
    "    vectors_product = tf.keras.layers.dot([user_vector, item_vector], axes=1, normalize=False)\n",
    "    # Model definition\n",
    "    model = tf.keras.models.Model(inputs=[user_id, item_id], outputs=[vectors_product], name='shallow_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_model(no_factors, no_users, no_items):\n",
    "    # User branch\n",
    "    user_id = tf.keras.layers.Input(shape=[1], name='user_id')\n",
    "    user_matrix = tf.keras.layers.Embedding(no_users+1, no_factors, name='user_matrix')(user_id)\n",
    "    user_vector = tf.keras.layers.Flatten(name='user_vector')(user_matrix)\n",
    "    # Item branch\n",
    "    item_id = tf.keras.layers.Input(shape=[1], name='item_id')\n",
    "    item_matrix = tf.keras.layers.Embedding(no_items+1, no_factors, name='item_matrix')(item_id)\n",
    "    item_vector = tf.keras.layers.Flatten(name='item_vector')(item_matrix)\n",
    "    # Concantenation\n",
    "    vectors_concat = tf.keras.layers.Concatenate()([user_vector, item_vector])\n",
    "    vectors_concat_dropout = tf.keras.layers.Dropout(0.2)(vectors_concat)\n",
    "    # Backbone \n",
    "    dense_1 = tf.keras.layers.Dense(16,name='fc3')(vectors_concat_dropout)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.2,name='d3')(dense_1)\n",
    "    dense_2 = tf.keras.layers.Dense(8,name='fc4', activation='relu')(dropout_1)\n",
    "    dense_2_output = tf.keras.layers.Dense(1, activation='relu', name='activation')(dense_2)\n",
    "    # Model definition\n",
    "    model = tf.keras.models.Model(inputs=[user_id, item_id], outputs=[dense_2_output], name='deep_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_factors=100\n",
    "model = create_deep_model(no_factors, no_users, no_items)\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [train_ratings.user_id, train_ratings.item_id]\n",
    "y_train = train_ratings.qcat_plays\n",
    "model.fit(X_train, y_train, validation_split=0.2,epochs=20, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [test_ratings.user_id, test_ratings.item_id]\n",
    "y_test = test_ratings.qcat_plays\n",
    "y_test_pred = model.predict(X_test, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = np.meshgrid(range(no_items),range(no_users))\n",
    "all_preds = model.predict([np.ravel(b), np.ravel(a)], batch_size=2048)\n",
    "all_preds = all_preds.reshape((no_users, no_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_user = 600\n",
    "\n",
    "predicted_best = all_preds[selected_user].argsort()[::-1][:5]\n",
    "print(df_1kfamous[df_1kfamous['item_id'].isin(predicted_best)][['artist-name','track-name']].drop_duplicates())\n",
    "df_1kfamous[df_1kfamous['user_id'] == selected_user].sort_values(ascending=False, by='plays')[['artist-name','track-name']].drop_duplicates().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('Test RMSE:', mean_squared_error(y_test.values, y_test_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
