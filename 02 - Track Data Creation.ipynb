{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the Notebook\n",
    "\n",
    "In this notebook, we query the Spotify API with the tracks in the 1k dataset after cleaning, which will serve us for the content based part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import tarfile\n",
    "from dask.delayed import delayed\n",
    "import scipy\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_tracks = pd.read_csv('data/famous_tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Collecting spotify data from track ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup spotipy client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"cf823e53fff345feae087ccdb549f8ff\",\n",
    "                                                           client_secret=\"9c45e47cbc55491290c90ef0821c7ea3\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to apply on the whole dataset to get the spotify Track ID as well as the genres of the artist that made the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotify_id_from_info(row, verbose=True, normalizer=None):\n",
    "    \n",
    "    artist_name = row[\"artist-name\"]\n",
    "    track_name  = row[\"track-name\"]\n",
    "    \n",
    "    if normalizer:\n",
    "        artist_name = normalizer(artist_name)\n",
    "        track_name  = normalizer(track_name)\n",
    "\n",
    "    search_query = f'artist:{artist_name} track:{track_name}'\n",
    "    \n",
    "    try:\n",
    "        results = sp.search(search_query, limit=1)\n",
    "        \n",
    "        track_id  = results['tracks']['items'][0]['id']\n",
    "        artist_id = results['tracks']['items'][0]['artists'][0]['id']\n",
    "        \n",
    "        genres = set(sp.artist(artist_id)['genres'])\n",
    "        \n",
    "        return track_id, artist_id, genres\n",
    "    \n",
    "    except:\n",
    "        if verbose:\n",
    "            print(f'Could not find information for \"{search_query}\"')\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying it to recover the spotify ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids withour normalizer\n",
    "# spotify_ids  = famous_tracks.reset_index().apply(spotify_id_from_info,axis=1)\n",
    "\n",
    "# add back spotify ids to our new dfs\n",
    "# spot_df = pd.DataFrame(list(spotify_ids), columns=['spotify-track-id', 'spotify-artist-id', 'genres'])\n",
    "\n",
    "# set back values\n",
    "# famous_tracks[['spotify-track-id', 'spotify-artist-id', 'genres']]     = spot_df.values\n",
    "\n",
    "# test_df = famous_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying it once again, this time removing non ascii character to recover some more spotify ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_df = test_df[test_df['spotify-artist-id'].isna()]\n",
    "\n",
    "# translator = str.maketrans('', '', string.punctuation)\n",
    "# normalizer = lambda s : unidecode(re.sub(r'\\(([^\\)]+)\\)', '', s)).translate(translator).strip()\n",
    "\n",
    "# spotify_id_normalizer = lambda x : spotify_id_from_info(x,normalizer=normalizer)\n",
    "\n",
    "# spotify_ids_normalized = na_df.reset_index().apply(spotify_id_normalizer, axis=1)\n",
    "\n",
    "# spot_norm_df = pd.DataFrame(list(spotify_ids_normalized), columns=['spotify-track-id', 'spotify-artist-id', 'genres'])\n",
    "\n",
    "# na_df[['spotify-track-id', 'spotify-artist-id', 'genres']] = spot_norm_df.values\n",
    "\n",
    "# test_df = test_df[['artist-name', 'plays', 'track-name', 'musicbrainz-artist-id', 'spotify-id', 'spotify-artist-id', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging back the lists of spotify ids recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idreducer = lambda x : x['spotify-id'] if x['spotify-id'] else x['spotify-idnorm']\n",
    "# artistreducer = lambda x : x['spotify-artist-id'] if x['spotify-artist-id'] else x['spotify-artist-idnorm']\n",
    "# genrereducer = lambda x : x['genres'] if x['genres'] else x['genresnorm']\n",
    "\n",
    "# test_df['spotify-id']        = test_df.join(na_df, rsuffix=\"norm\")[['spotify-id', 'spotify-idnorm']].apply(idreducer, axis=1)\n",
    "# test_df['spotify-artist-id'] = test_df.join(na_df, rsuffix=\"norm\")[['spotify-artist-id', 'spotify-artist-idnorm']].apply(artistreducer, axis=1)\n",
    "# test_df['genres']            = test_df.join(na_df, rsuffix=\"norm\")[['genres', 'genresnorm']].apply(genrereducer, axis=1)\n",
    "\n",
    "# test_df = test_df[['artist-name', 'plays', 'track-name', 'musicbrainz-artist-id', 'spotify-id', 'spotify-artist-id', 'genres']]\n",
    "# test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Spotify audio features from the id and joining back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = test_df['spotify-id'].apply(lambda x : sp.audio_features([x]))\n",
    "\n",
    "# features_df = pd.DataFrame([x[0] for x in features.values])\n",
    "# features_df = features_df.set_index(features.index)\n",
    "\n",
    "# joint_df = features_df.join(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Audio Features for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint_df.to_pickle('data/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint_df.to_csv('data/features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovering genres per track, and saving it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = set()\n",
    "# def f(x):\n",
    "#     global test\n",
    "#     test = test.union(x)\n",
    "#     return x\n",
    "# recovered.genres.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovered = pd.read_pickle('data/features.pkl')\n",
    "# recovered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create User/Track DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out tnon famous tracks\n",
    "# df_1kfamous  = df_1k.dropna()[df_1k.dropna()['musicbrainz-track-id'].isin(list(famous_tracks.index))]\n",
    "#Filter out tracks not in spotify result\n",
    "# df_1kfamous = df_1kfamous[df_1kfamous['musicbrainz-track-id'].isin(list(recovered.index))]\n",
    "# df_1kfamous = df_1kfamous.groupby(['userid', 'musicbrainz-artist-id','musicbrainz-track-id']).agg((lambda x : x.iloc[0], lambda x : len(x)))\n",
    "# df_1kfamous.columns = ['timestamp','plays','artist-name','tnorm1', 'track-name','tnorm2']\n",
    "# df_1kfamous = df_1kfamous.reset_index().drop(['tnorm1', 'tnorm2'],axis=1)\n",
    "# df_1kfamous.rename(columns = {'userid':'user-id','musicbrainz-track-id':'track-id'}, inplace = True)\n",
    "# df_1kfamous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1kfamous.to_csv('data/df_1ktfamous.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
